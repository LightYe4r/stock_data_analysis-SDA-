{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da3fa1c2-726d-41b6-b7cf-538ba40418bc",
   "metadata": {},
   "source": [
    "##  import Beautifulsoup, request, selenium 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17c795a6-7b89-4236-b718-8661e3f9b39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, element\n",
    "import chardet\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time \n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import urllib3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79cf3c1-0971-43d3-a2a0-541817ccbc95",
   "metadata": {},
   "source": [
    "## 네이버 크롤링 위해 고정 header 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "043cfbdd-3cee-4b7e-aef0-479589c2c816",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}\n",
    "resultList = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538f4447-4b59-454b-9baa-971af910b243",
   "metadata": {},
   "source": [
    "## Chrome 드라이버 생성 , headless 모드(웹브라우저 실행없이)로 실행, SSSL 인증서 오류 무시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd61e373-77f3-43ee-9856-94023ee88d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  \n",
    "chrome_options.add_argument('--ignore-certificate-errors') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091401e2-913b-4ad1-8f06-4df8c9849321",
   "metadata": {},
   "source": [
    "#   크롤링 함수 정의 \n",
    "### 뉴스 검색 사이트 URL 부분의 검색명에 {회사 이름}를 넣어줌  \n",
    "### 뉴스 제목, 뉴스 날짜, 언론사, 뉴스 내용을 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aba1986a-1842-4b23-89d5-dd55a14896c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_crawl(start_date, end_date,company):\n",
    "    global news_date\n",
    "    start_date_nospace = start_date.replace('.', '')\n",
    "    end_date_nopspace = end_date.replace('.', '')\n",
    "    current_page = 1\n",
    "    searching = True\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.implicitly_wait(5)\n",
    "\n",
    "    search_urlback = f\"{start_date}&de={end_date}&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:from{start_date_nospace}to{end_date_nopspace},a:all&start=1\"\n",
    "    search_urlfront = f\"https://search.naver.com/search.naver?where=news&query={company}&sm=tab_opt&sort=2&photo=0&field=0&pd=3&ds=\"\n",
    "    search_url = search_urlfront + search_urlback\n",
    "    print(search_url)\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    # 새로운 컨텐츠가 로드될 때까지 대기\n",
    "    while True:\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            last_height = new_height\n",
    "            continue \n",
    "        else:\n",
    "            last_height = new_height\n",
    "            break\n",
    "\n",
    "    naver_html_src = driver.page_source\n",
    "    naver_soup = BeautifulSoup(naver_html_src, 'html.parser')\n",
    "    pages = naver_soup.find('div', {'class' : 'sc_page_inner'})\n",
    "    news_list = naver_soup.select('li[class=\"bx\"]')\n",
    "\n",
    "    for news in news_list:\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # 뉴스 제목\n",
    "        try :\n",
    "            news_title = news.find('a', attrs={'class':'news_tit'}).get('title')\n",
    "        except AttributeError:\n",
    "            news_title = \"No title available\"\n",
    "        news_url = news.find('a', attrs={'class':'news_tit'}).get('href')\n",
    "\n",
    "        # 뉴스 날짜 \n",
    "        find_date = news.find_all('span', attrs={'class':'info'})\n",
    "        if len(find_date) > 1:\n",
    "            # if find_date == \"4주 전\":\n",
    "            #     news_date = 20240212\n",
    "            # elif find_date == \"3주 전\":\n",
    "            #     news_date = 20240219\n",
    "            # elif find_date == \"2주 전\":\n",
    "            #     news_date = 20240226\n",
    "            # elif find_date == \"1주 전\":\n",
    "            #     news_date = 20240303\n",
    "            # elif find_date == \"*일 전\":\n",
    "            #     news_date = 20240312\n",
    "            # else :                \n",
    "            news_date = find_date[1].text\n",
    "        else: \n",
    "            news_date = find_date[0].text\n",
    "            \n",
    "        # 뉴스 발행사 \n",
    "        try:\n",
    "            news_publisher = news.find('a', attrs={'class':'info press'}).text\n",
    "        except:\n",
    "            try:\n",
    "                news_publisher = news.find('a', attrs={'class':'info'}).text\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "        # 뉴스 내용\n",
    "        news_summary = news.find('a', attrs={'class':'api_txt_lines dsc_txt_wrap'}).text\n",
    "        news_summary = news_summary[0:50]\n",
    "        \n",
    "        news_text = []\n",
    "        try:\n",
    "            news_response = requests.get(news_url, headers=headers)\n",
    "        except :\n",
    "            continue\n",
    "\n",
    "        if news_summary in str(news_response.text):\n",
    "            news_soup = BeautifulSoup(news_response.text, 'html.parser')\n",
    "        else:\n",
    "            news_soup = BeautifulSoup(news_response.content.decode('euc-kr', 'replace'), 'html.parser')\n",
    "            \n",
    "        news_content = str(news_soup.text).split('\\n')\n",
    "        news_index = [i for i, s in enumerate(news_content) if news_summary in s]\n",
    "        \n",
    "        if news_index:\n",
    "            news_index = news_index[0]\n",
    "            punctuations = ['.', ',', '?', '!']\n",
    "            count = 0\n",
    "            if news_index != 0:\n",
    "                for i in reversed(range(0, news_index)):\n",
    "                    if any(text in news_content[i] for text in punctuations): \n",
    "                        news_text.append(news_content[i])\n",
    "                        count = 0\n",
    "                        #print(\"i\", i, \"count\", count)\n",
    "                        #print(news_content[i])\n",
    "                    else:\n",
    "                        count +=1\n",
    "                    if count > 3:\n",
    "                        break\n",
    "\n",
    "            # print(news_index)\n",
    "\n",
    "            if news_text:\n",
    "                news_text.reverse()\n",
    "            count = 0\n",
    "            news_text.append(news_content[news_index])\n",
    "            for i in range(news_index, len(news_content)):\n",
    "                \n",
    "                if any(text in news_content[i] for text in punctuations): \n",
    "                    news_text.append(news_content[i])\n",
    "                    count = 0\n",
    "\n",
    "                else:\n",
    "                    count +=1\n",
    "                if count > 3:\n",
    "                    break\n",
    "            \n",
    "            news_text = ' '.join(news_text)\n",
    "        resultList.append([news_date, news_title, news_text, news_publisher])\n",
    "        df = pd.DataFrame(resultList)\n",
    "\n",
    "        # updated_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "        df.to_csv(f'news_{company}1.csv', encoding='utf-8-sig', index=False)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return news_text, news_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf31a20e-eb82-469e-bcf4-fa87833eb5bd",
   "metadata": {},
   "source": [
    "# 함수 실행\n",
    "### 시작날짜, 끝날짜, 회사이름\n",
    "### 중간에 언론사 or 네이버 서버에 의해 네트워크 중지되었다는 오류 발생할 수도 있음-=> .py로 실행\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "128aa299-3a1f-453a-b4a4-acd2743c5daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://search.naver.com/search.naver?where=news&query=동진쎄미켐&sm=tab_opt&sort=2&photo=0&field=0&pd=3&ds=20240101&de=20240102&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so:r,p:from20240101to20240102,a:all&start=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'zmq.backend.cython.message.Frame.__dealloc__'\n",
      "Traceback (most recent call last):\n",
      "  File \"zmq\\\\backend\\\\cython\\\\checkrc.pxd\", line 13, in zmq.backend.cython.checkrc._check_rc\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 실행\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mstart_crawl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m20240101\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m20240102\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m동진쎄미켐\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[38], line 19\u001b[0m, in \u001b[0;36mstart_crawl\u001b[1;34m(start_date, end_date, company)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 새로운 컨텐츠가 로드될 때까지 대기\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     new_height \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_script\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreturn document.body.scrollHeight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_height \u001b[38;5;241m==\u001b[39m last_height:\n\u001b[0;32m     21\u001b[0m         last_height \u001b[38;5;241m=\u001b[39m new_height\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:407\u001b[0m, in \u001b[0;36mWebDriver.execute_script\u001b[1;34m(self, script, *args)\u001b[0m\n\u001b[0;32m    404\u001b[0m converted_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(args)\n\u001b[0;32m    405\u001b[0m command \u001b[38;5;241m=\u001b[39m Command\u001b[38;5;241m.\u001b[39mW3C_EXECUTE_SCRIPT\n\u001b[1;32m--> 407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscript\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscript\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverted_args\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:345\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m    343\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[1;32m--> 345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:302\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    300\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[0;32m    301\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[1;32m--> 302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:322\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    319\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 322\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\_request_methods.py:144\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[0;32m    137\u001b[0m         method,\n\u001b[0;32m    138\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw,\n\u001b[0;32m    142\u001b[0m     )\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\_request_methods.py:279\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    275\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_type)\n\u001b[0;32m    277\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\poolmanager.py:444\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    442\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    446\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    790\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    809\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connection.py:466\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    465\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    469\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:1423\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1422\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1423\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1425\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 실행\n",
    "start_crawl('20240101','20240102','동진쎄미켐')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a264bc9-8d57-42b9-ad09-0f560199960c",
   "metadata": {},
   "source": [
    "# 크롤링 파일 합치기\n",
    "# 파일들의 리스트를 얻음\n",
    "# 각 파일을 DataFrame으로 읽은 후 리스트에 저장\n",
    "# 병합된 DataFrame을 CSV 파일로 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "add017f8-bc5f-4883-9641-694b0f601b8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m file_list \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnews_*.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m dfs \u001b[38;5;241m=\u001b[39m [pd\u001b[38;5;241m.\u001b[39mread_csv(file) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m file_list]\n\u001b[1;32m----> 9\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m merged_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewslast.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8-sig\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "\n",
    "file_list = glob.glob(f'news_*.csv')\n",
    "\n",
    "dfs = [pd.read_csv(file) for file in file_list]\n",
    "\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "merged_df.to_csv(f'newslast.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c9297b-fe48-43b4-968e-8802c5a983ef",
   "metadata": {},
   "source": [
    "# installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c09f324-610d-4a0e-8d00-adabd77535fc",
   "metadata": {},
   "source": [
    "## konlpy를 위한 jdk 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998b27d4-f4b5-4f2e-91b2-00399105060b",
   "metadata": {},
   "source": [
    "https://www.oracle.com/kr/java/technologies/javase/javase8u211-later-archive-downloads.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ba6237-3569-45e5-a08b-4d5478d3b3a1",
   "metadata": {},
   "source": [
    "윈도우 > 시스템 환경 변수 편집 > 환경변수 > 시스템 변수 > 새로 만들기\n",
    "\n",
    "변수 : JAVA_HOME         \n",
    "값(jdk 설치 경로) : C:\\Program Files\\Java\\jdk-1.8\n",
    "\n",
    "윈도우 > 시스템 환경 변수 편집 > 환경변수 > 시스템 변수 > Path > 편집 > 새로 만들기             \n",
    "                          \n",
    "%JAVA_HOME%\\bin;\n",
    "\n",
    "윈도우 cmd에서 $java -version      \n",
    "으로 설치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a07c4a4a-9c73-4759-82b5-6ec678ce5a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0ed859a-5443-49e1-b0d0-1aebad605807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wordcloud) (1.26.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wordcloud) (10.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wordcloud) (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Requirement already satisfied: kss in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.5.4)\n",
      "Requirement already satisfied: emoji==1.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kss) (1.2.0)\n",
      "Requirement already satisfied: regex in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kss) (2023.12.25)\n",
      "Requirement already satisfied: pecab in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kss) (1.0.8)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kss) (3.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pecab->kss) (1.26.4)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pecab->kss) (15.0.1)\n",
      "Requirement already satisfied: pytest in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pecab->kss) (8.1.1)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytest->pecab->kss) (2.0.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytest->pecab->kss) (24.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=1.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytest->pecab->kss) (1.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytest->pecab->kss) (0.4.6)\n",
      "Requirement already satisfied: konlpy in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from konlpy) (1.5.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from konlpy) (5.1.0)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from konlpy) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (24.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: selenium in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.18.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.1)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.24.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (4.10.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (3.6)\n",
      "Requirement already satisfied: outcome in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud\n",
    "!pip install kss\n",
    "!pip install konlpy\n",
    "!pip install scikit-learn\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21047d06-d023-4744-a055-86a1829ee4aa",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17d1177-9ea2-49a8-91ba-25a65ac905c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import base64\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "import certifi\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "font_fname = 'C:/Windows/Fonts/malgun.ttf'\n",
    "font_family = font_manager.FontProperties(fname=font_fname).get_name()\n",
    "plt.rcParams['font.family'] = font_family\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import kss\n",
    "from konlpy.tag import Okt, Kkma\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0992b810-8380-41a9-9246-1211951ed374",
   "metadata": {},
   "source": [
    "# 필요한 파일 준비\n",
    "\n",
    "## stopwords-ko.txt 파일과 같은 경로에 다운로드\n",
    "\n",
    "## 파일과 같은 경로에 wordcloud_mask.png 이름의 wordcloud 생성을 위한 mask 이미지 저장\n",
    "\n",
    "# Text에서 stopwords 제거 및 문장 자르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625b0946-dd57-4927-b7dc-b31729d3853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.okt = Okt()\n",
    "        self.kkma = Kkma()\n",
    "        self.stopwords = []\n",
    "        stopwords_path = './stopwords-ko.txt'\n",
    "        with open(stopwords_path, 'r', encoding='UTF8') as file:\n",
    "            for line in file:\n",
    "                self.stopwords.append(line.strip())\n",
    "\n",
    "    def text2sentences(self, text):\n",
    "        sentences = kss.split_sentences(text)\n",
    "        return sentences\n",
    "        \n",
    "    def sentences2nouns(self, sentences):\n",
    "        nouns = []\n",
    "        for sentence in sentences:\n",
    "            for word in self.okt.nouns(str(sentence)):\n",
    "                if word in self.stopwords or len(word) <= 1:\n",
    "                    continue    \n",
    "                if word in nouns:\n",
    "                    continue\n",
    "                nouns.append(word)\n",
    "        return nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59de07e-c536-4f1a-a81a-7a60adaaa6aa",
   "metadata": {},
   "source": [
    "#  단어 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250fd66a-7170-4415-a2aa-04d86f03b07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.text_analyze = TextAnalyzer()\n",
    "        self.countvec = CountVectorizer()\n",
    "        self.okt = Okt()\n",
    "        self.stoptags = ['Determiner', 'Adverb', 'Conjunction', 'Exclamation', 'Josa']\n",
    "        self.counttags = ['Noun', 'Verb', 'Adjective']\n",
    "        self.essential_josa = ['은', '는', '이', '가', '을', '를']\n",
    "        \n",
    "    def build_word_graph(self, sentence):\n",
    "        countvec_mat = normalize(self.countvec.fit_transform(sentence).toarray().astype(float), axis=0)\n",
    "        vocab = self.countvec.vocabulary_\n",
    "        return np.dot(countvec_mat.T, countvec_mat), {vocab[word]: word for word in vocab}\n",
    "    \n",
    "    def get_ranks(self, graph, d=0.85):\n",
    "        A = graph\n",
    "        matrix_size = A.shape[0]\n",
    "        for id in range(matrix_size):\n",
    "            A[id, id] = 0    \n",
    "            link_sum = np.sum(A[:, id])\n",
    "            if link_sum != 0:\n",
    "                A[:, id] /= link_sum\n",
    "            A[:, id] *= -d\n",
    "            A[id, id] = 1\n",
    "            \n",
    "        B = (1-d) * np.ones((matrix_size, 1))\n",
    "        ranks = np.linalg.solve(A, B)\n",
    "        return {idx: r[0] for idx, r in enumerate(ranks)}\n",
    "\n",
    "    # 키워드\n",
    "    def text2keywords(self, text, word_num=15):        \n",
    "        sentences = self.text_analyze.text2sentences(text)\n",
    "        nouns = self.text_analyze.sentences2nouns(sentences)\n",
    "        word_graph, idx2word = self.build_word_graph(nouns)\n",
    "        word_rank_idx = self.get_ranks(word_graph)\n",
    "        sorted_word_rank_idx = sorted(word_rank_idx, key=lambda k: word_rank_idx[k], reverse=True)\n",
    "        \n",
    "        keywords = []\n",
    "        index = []\n",
    "        \n",
    "        for idx in sorted_word_rank_idx[:word_num]:\n",
    "            index.append(idx)\n",
    "        for idx in index:\n",
    "            keywords.append(idx2word[idx])\n",
    "        return keywords\n",
    "    \n",
    "    # 품사 태깅\n",
    "    def text2postag(self, text):\n",
    "        postag = self.okt.pos(text)\n",
    "        return postag\n",
    "    \n",
    "    # 빈도수 높은 단어\n",
    "    def text2countwords(self, text):\n",
    "        postag = self.text2postag(text)\n",
    "        countwords_postag = []\n",
    "        \n",
    "        for i in range(len(postag)):\n",
    "            if postag[i][1] in self.counttags:\n",
    "                countwords_postag.append(postag[i][0])\n",
    "        return countwords_postag\n",
    "    \n",
    "    # visualization\n",
    "    def words2wordscount(self, words, counttype):\n",
    "        if counttype == 'individual':\n",
    "            whole = []\n",
    "            for i in range(len(words)):\n",
    "                for j in range(0, len(words)-i, 1):\n",
    "                    whole.append(words[i])\n",
    "            words = whole\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # 모든 경우에서 count를 통해 dict 생성\n",
    "        count = Counter(words)\n",
    "        wordscount = dict(count.most_common())\n",
    "        # countwoords 선정시 단어 길이, 빈도수 1인 단어 제거\n",
    "        if counttype == 'count':\n",
    "            dict_key = list(wordscount.keys())\n",
    "            for i in dict_key:\n",
    "                if wordscount[i] == 1:\n",
    "                    del(wordscount[i])\n",
    "        else:\n",
    "            pass\n",
    "        return wordscount\n",
    "    \n",
    "\n",
    "\n",
    "    # 워드클라우드 시각화\n",
    "    def visualize_wordcloud(self, text, wordtype):\n",
    "        #wordcloud_path = os.getcwd()+'\\\\server\\\\routers\\\\text_analysis'\n",
    "        wordcloud_path = '.'\n",
    "        img_save_path = '.'\n",
    "        if wordtype == 'keywords':\n",
    "            mask = np.array(Image.open(wordcloud_path+'/기영이.jpg'))\n",
    "            words = self.text2keywords(text)\n",
    "            words = self.words2wordscount(words, 'individual')\n",
    "        \n",
    "        elif wordtype == 'countwords':\n",
    "            mask = np.array(Image.open(wordcloud_path+'/기영이.jpg'))\n",
    "            words = self.text2countwords(text)\n",
    "            words = self.words2wordscount(words, 'count')\n",
    "        \n",
    "        image_colors = ImageColorGenerator(mask)\n",
    "        wordcloud = WordCloud(font_path=font_fname, background_color='white',\n",
    "                              mask=mask, width=mask.shape[1], height=mask.shape[0], prefer_horizontal=0.99999)\n",
    "        cloud = wordcloud.generate_from_frequencies(words)\n",
    "        \n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.imshow(cloud.recolor(color_func=image_colors), interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.savefig(img_save_path+f'/text_wordcloud_{wordtype}.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8277bd51-6069-4c30-945d-3c366b49fcf9",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269dc0a6-eee8-47a6-b7ac-04bf1a49a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "company = \"피에스케이\"\n",
    "news = pd.read_csv(f'news{company}last.csv', encoding='utf-8-sig')\n",
    "news_title = news[\"1\"].str.strip()\n",
    "news_title_value = ' '.join(news_title.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5535a64f-f479-414d-9024-547d76e9c884",
   "metadata": {},
   "source": [
    "# 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5422689c-80fc-4052-9667-389424176338",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'news_title_value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     stttext \u001b[38;5;241m=\u001b[39m \u001b[43mnews_title_value\u001b[49m\n\u001b[0;32m      3\u001b[0m     img_save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m     TA \u001b[38;5;241m=\u001b[39m TextAnalyzer()     \u001b[38;5;66;03m# 텍스트 분석 클래스\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'news_title_value' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    stttext = news_title_value\n",
    "    img_save_path = '-'\n",
    "    \n",
    "    TA = TextAnalyzer()     # 텍스트 분석 클래스\n",
    "    WA = WordAnalyzer()     # 단어 분석 클래스\n",
    "\n",
    "    keywords      = WA.text2keywords(stttext)                   \n",
    "    top3_keywords = list(WA.words2wordscount(keywords, 'individual'))[:3]         # 키워드 상위 3개\n",
    "    countwords      = WA.text2countwords(stttext)                 \n",
    "    top3_countwords = list(WA.words2wordscount(countwords, 'countwords'))[:3]     # 빈도수 높은 단어 상위 3개\n",
    "    WA.visualize_wordcloud(stttext, 'keywords')       # 키워드 워드클라우드\n",
    "    WA.visualize_wordcloud(stttext, 'countwords')     # 빈도수 높은 단어 워드클라우드\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1b3d6c-add0-4f24-887c-11772ec383e7",
   "metadata": {},
   "source": [
    "# pytorch, tensorflow 설치하기 싫으니 colab으로 실행 해준다\n",
    "## 허깅페이스 api 사용 => pipeline(\"task\", \"모델명\")\n",
    "## 예시 sentiment_classification(\"today is payday!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be42af-3e73-4ca5-8cc0-a5ba863dbdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment_classification = pipeline(\"text-classification\", \"snunlp/KR-FinBert-SC\")\n",
    "\n",
    "import pandas as pd \n",
    "# sentiment_classification(\"today is payday!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f245fd09-fc46-4cbf-846a-237bc047d9e6",
   "metadata": {},
   "source": [
    "## 해당하는 회사 이름 csv 불러오기 (경로 확인하기, 파일을 꼭 colab에 업로드해 줘야함!!), 열 이름 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "73fc6630-5328-4a37-a0ac-db8d57aad0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "company = \"DB하이텍\"\n",
    "news = pd.read_csv(f'/content/news{company}last.csv', encoding='utf-8-sig')\n",
    "news.rename(columns={news.columns[0] : '날짜', \n",
    "                          news.columns[1] : '제목', \n",
    "                          news.columns[2] : '내용', \n",
    "                          news.columns[3] : '언론사'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f817d2d7-d532-44b5-904f-62c716e5dc7b",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e069f19-afe9-465b-a166-139a36db8470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수 정의\n",
    "def preprocess_text(text):\n",
    "    # 괄호와 괄호 안 문자 제거\n",
    "    text = re.sub(r'\\([^)]*\\)', ' ', text)\n",
    "    # '...' 제거\n",
    "    text = text.replace('...', ' ')\n",
    "    return text\n",
    "news_data = news[\"1\"].apply(preprocess_text)\n",
    "print(news_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152ead59-a344-429f-b30a-50a0a891eea7",
   "metadata": {},
   "source": [
    "## 뉴스 제목과 뉴스 내용 뽑아오기\n",
    "## 뉴스 데이터 중에서 해당 회사 이름이 포함된 내용만 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "535e7b06-3efd-4b72-83b9-d9408ce51f86",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3855880390.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[50], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    if news_data True:\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 뉴스 제목 열 가져오기\n",
    "news_title = news[\"1\"].str.strip()\n",
    "# print(news_title)\n",
    "news_data = news_title.str.contains(company)\n",
    "if news_data True:\n",
    "\n",
    "  print(news_title)\n",
    "# news_data = news_title.str.contains(company)\n",
    "# news_title = news.loc[:, \"1\"]\n",
    "# print(news_data)\n",
    "\n",
    "# news_content = news[[\"1\",\"2\"]]\n",
    "# print(news_content)\n",
    "\n",
    "\n",
    "# news_title_value = ' '.join(news_title.values)\n",
    "# news_title_value = news_title.values.tolist()\n",
    "# print(news_title_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1f6332a-5728-4b01-8801-94192bff5adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecb29ae-593b-42da-9436-4681c6a4afbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_classification(news_title_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
