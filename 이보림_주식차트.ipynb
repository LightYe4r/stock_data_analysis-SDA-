{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LightYe4r/stock_data_analysis-SDA-/blob/master/%EC%9D%B4%EB%B3%B4%EB%A6%BC_%EC%A3%BC%EC%8B%9D%EC%B0%A8%ED%8A%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCI72lQKK5bf"
      },
      "source": [
        "아래 설치 후 런타임 재시작(세션 재시작)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFIhTWgGFYcV"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtV3vuc2K0rf"
      },
      "source": [
        "# 네이버 증권에서 반도체 관련 종목 가져오기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yffOweBjK5_"
      },
      "source": [
        "- Google Drive 마운트 하기\n",
        "- Google Drive에서 Colab Notebooks 폴더 > 반도체주식 폴더 생성 후 네이버증권_반도체종목.txt 파일 위치하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCkcsdZ6K77m"
      },
      "outputs": [],
      "source": [
        "stock = {}\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/반도체주식/네이버증권_반도체종목.txt','r') as f:\n",
        "  lines = f.readlines()\n",
        "  print(lines)\n",
        "  for idx, line in enumerate(lines[::6]):\n",
        "    stock[line.strip()] = lines[idx*6+1].strip()\n",
        "print(stock)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0vjkzcXBFLP"
      },
      "outputs": [],
      "source": [
        "print(len(stock))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBGxfv3PFqca"
      },
      "outputs": [],
      "source": [
        "#!pip install finance-datareader\n",
        "#!pip install beautifulsoup4\n",
        "#!pip install matplotlib\n",
        "#!pip install pandas_ta\n",
        "#!pip install plotly==5.11.0\n",
        "#!pip install pandas_datareader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PC_P8HiVZp5y"
      },
      "outputs": [],
      "source": [
        "import FinanceDataReader as fdr\n",
        "import pandas as pd\n",
        "import pandas_datareader.data as pdr\n",
        "import pandas_ta as ta\n",
        "import numpy as np\n",
        "from matplotlib import gridspec\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "\n",
        "\n",
        "from datetime import datetime, date\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pre-processing"
      ],
      "metadata": {
        "id": "N4B7XJRLTZ3D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sT3mR8CIbl67"
      },
      "outputs": [],
      "source": [
        "stock_data = {}\n",
        "def downlaod_stockdata():\n",
        "  global stock_data\n",
        "  for value in stock.values():\n",
        "    df = fdr.DataReader(value)\n",
        "    stock_data[value] = df\n",
        "\n",
        "krx = fdr.StockListing('KRX')\n",
        "downlaod_stockdata()\n",
        "\n",
        "def get_stockdata(stock_code):\n",
        "  global stock_data\n",
        "  # 개장하지 않은 날 0인 데이터를 전 날 데이터로 채움\n",
        "  stock_data[stock_code].replace(0,np.nan,inplace=True)\n",
        "  stock_data[stock_code] = stock_data[stock_code].ffill()\n",
        "  return stock_data[stock_code]\n",
        "  # stock_data = pdr.get_data_yahoo(stock_code+'.KQ')\n",
        "  # if stock_data.empty:\n",
        "  #   stock_data = pdr.get_data_yahoo(stock_code+'.KS')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIy2drUc9_FR"
      },
      "outputs": [],
      "source": [
        "buttons = []\n",
        "for val in stock.keys():\n",
        "  button = dict()\n",
        "  button['args'] = ['type',val]\n",
        "  button['label'] = val\n",
        "  button['method'] = 'update'\n",
        "  buttons.append(button)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 재무제표와 합치기"
      ],
      "metadata": {
        "id": "vUo7PWyq-xq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stock_df.loc[:datetime.strptime('2023/04','%Y/%m'),'매출액']"
      ],
      "metadata": {
        "id": "UQ-ih72dbm4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(df.index))"
      ],
      "metadata": {
        "id": "37DUiF9ydsnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/Colab Notebooks/반도체주식/data_csv/'\n",
        "def merge_files(col_name):\n",
        "  for name, value in stock.items():\n",
        "    df = pd.read_csv(file_path+'A'+value+'.csv',header = 0,index_col=0)\n",
        "    stock_df = stock_data[value]\n",
        "\n",
        "    reverse_idx_date = ''\n",
        "    for idx, idx_date in enumerate(list(df.index)):\n",
        "      if idx == 0:\n",
        "        stock_df.loc[:datetime.strptime(idx_date,'%Y/%m')+relativedelta(months=1),col_name] = df.loc[idx_date,col_name]\n",
        "        reverse_idx_date = idx_date\n",
        "      elif idx_date == list(df.index)[-1] :\n",
        "        stock_df.loc[datetime.strptime(idx_date,'%Y/%m'):,col_name] = df.loc[idx_date,col_name]\n",
        "      else:\n",
        "        stock_df.loc[datetime.strptime(reverse_idx_date,'%Y/%m')+relativedelta(months=1):datetime.strptime(idx_date,'%Y/%m')+relativedelta(months=1),col_name] = df.loc[idx_date,col_name]\n",
        "        reverse_idx_date = idx_date\n",
        "    print(stock_df)\n"
      ],
      "metadata": {
        "id": "ryWBjKc1-1Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROA = 'ROA(%)(당기순이익(연율화) / 총자산(평균)) * 100ROA'\n",
        "ROE = 'ROE(%)(지배주주순이익(연율화) / 지배주주지분(평균)) * 100ROE'\n",
        "EPS = 'EPS(원)지배주주순이익 / 수정평균주식수EPS(원)'\n",
        "BPS = 'BPS(원)지배주주순자산(자사주차감전) / 수정기말주식수BPS(원)'\n",
        "PER = 'PER(배)수정주가(보통주) / 수정EPSPER'\n",
        "PBR = 'PBR(배)수정주가(보통주) / 수정BPSPBR'\n",
        "stock_num = '발행주식수'\n",
        "\n",
        "\n",
        "financial_statement_list = ['매출액','영업이익','당기순이익'\n",
        "                        ,'자산총계','부채총계','자본총계',ROA\n",
        "                            ,ROE,EPS,BPS,PER,PBR,stock_num]\n",
        "for f in financial_statement_list:\n",
        "  merge_files(f)"
      ],
      "metadata": {
        "id": "HeAhAJDEZml5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ORo5R_tPkSsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_na(stock_code):\n",
        "  get_stockdata(stock_code).dropna(axis=1,inplace=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "M5lRR1qujUKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_na('389020')\n",
        "stock_data['389020']"
      ],
      "metadata": {
        "id": "2qKacqsYkaN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "coAmp7DrkX22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_columns(columns):\n",
        "  for col in columns:\n",
        "    for name, value in stock.items():\n",
        "      stock_data[value]\n"
      ],
      "metadata": {
        "id": "jcfl5zh9cwvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# visualization"
      ],
      "metadata": {
        "id": "syk4e3k8CuIm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWpSNbf0brFJ"
      },
      "outputs": [],
      "source": [
        "def match_dfshape(df, start_date, end_date):\n",
        "    # 주어진 기간 동안의 모든 날짜 생성\n",
        "    expected_dates = pd.date_range(start=start_date, end=end_date)\n",
        "\n",
        "    # 주식 DataFrame에 없는 날짜에 대한 데이터 생성\n",
        "    missing_dates_data = pd.DataFrame(index=expected_dates, columns=df.columns)\n",
        "\n",
        "    # 주식 DataFrame과 결합하여 결측치를 채움\n",
        "    filled_df = pd.concat([df, missing_dates_data]).sort_index()\n",
        "\n",
        "    filled_df.fillna(method='ffill', inplace=True)  # 이전 값으로 결측치 채우기\n",
        "    filled_df.fillna(0, inplace=True)\n",
        "    # 주어진 기간 동안의 데이터 추출\n",
        "    filtered_data = filled_df.loc[start_date:end_date]\n",
        "\n",
        "    return filtered_data\n",
        "\n",
        "def cal_sma_ema_rsi(df):\n",
        "  df['Change']=df['Close']-df['Open']\n",
        "  df.loc[df['Change']>=0,'Volumecolor']=1\n",
        "  df.loc[df['Change']<0,'Volumecolor']=0\n",
        "  df[['Change','Volumecolor']]\n",
        "\n",
        "  # 단순 이동평균\n",
        "  df.loc[:, 'SMA_20'] = ta.sma(df['Close'],length=20)\n",
        "  df.loc[:, 'SMA_60'] = ta.sma(df['Close'],length=60)\n",
        "\n",
        "  # 지수 이동평균\n",
        "  df.loc[:, 'EMA_20'] = ta.ema(df['Close'], 20)\n",
        "  df.loc[:, 'EMA_60'] = ta.ema(df['Close'], 60)\n",
        "\n",
        "  df.loc[:, 'RSI_14'] = ta.rsi(df['Close'], length=14)\n",
        "  df.loc[:, 'RSI_14'] = df['RSI_14'].fillna(0)\n",
        "  return df\n",
        "\n",
        "def draw_candlechart(df):\n",
        "  df['Change']=df['Close']-df['Open']\n",
        "  df.loc[df['Change']>=0,'Volumecolor']=1\n",
        "  df.loc[df['Change']<0,'Volumecolor']=0\n",
        "  df[['Change','Volumecolor']]\n",
        "  fig = make_subplots(rows=2,\n",
        "                      cols=1,\n",
        "                      shared_xaxes=True,\n",
        "                      )\n",
        "\n",
        "  fig = make_subplots(rows=2, cols=1)\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Candlestick(x=df.index,\n",
        "                  open=df['Open'],\n",
        "                  high=df['High'],\n",
        "                  low=df['Low'],\n",
        "                  close=df['Close'],\n",
        "                  increasing_line_color= 'red', decreasing_line_color= 'blue',\n",
        "                  name='주가'\n",
        "                  ),\n",
        "                  row=1, col=1\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Bar(x=df.index, y=df['Volume'],\n",
        "            marker=dict(color=df['Volumecolor'],colorscale='BlueRed'),\n",
        "            name='거래량'),\n",
        "      row=2, col=1\n",
        "  )\n",
        "\n",
        "  fig.update(layout_xaxis_rangeslider_visible=False)\n",
        "\n",
        "  fig.show()\n",
        "\n",
        "def draw_sma_ema(name,df):\n",
        "  df = cal_sma_ema_rsi(df)\n",
        "\n",
        "  fig = make_subplots(rows=2,\n",
        "                      cols=1,\n",
        "                      shared_xaxes=True,\n",
        "                      vertical_spacing=0.1)\n",
        "\n",
        "  fig = make_subplots(rows=2, cols=1)\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Candlestick(x=df.index,\n",
        "                  open=df['Open'],\n",
        "                  high=df['High'],\n",
        "                  low=df['Low'],\n",
        "                  close=df['Close'],\n",
        "                  increasing_line_color= 'red', decreasing_line_color= 'blue',\n",
        "                  name='주가'\n",
        "                  ),\n",
        "                  row=1, col=1\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Scatter(x=df.index, y=df['SMA_20'],\n",
        "                line=dict(color=\"#b66aa0\"),\n",
        "                name='SMA_20'),\n",
        "      row=1, col=1\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Scatter(x=df.index, y=df['SMA_60'],\n",
        "                line=dict(color=\"#414b73\"),\n",
        "                  name='SMA_60'),\n",
        "      row=1, col=1\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Scatter(x=df.index, y=df['EMA_20'],\n",
        "                line=dict(color=\"#8b8b8b\"),\n",
        "                  name='EMA_20'),\n",
        "      row=1, col=1\n",
        "  )\n",
        "\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Scatter(x=df.index, y=df['EMA_60'],\n",
        "                line=dict(color=\"#e8d887\"),\n",
        "                  name='EMA_60'),\n",
        "      row=1, col=1\n",
        "  )\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Bar(x=df.index, y=df['Volume'],\n",
        "            marker=dict(color=df['Volumecolor'],colorscale='BlueRed'),\n",
        "            name='거래량'),\n",
        "      row=2, col=1\n",
        "  )\n",
        "\n",
        "  fig.update(layout_xaxis_rangeslider_visible=False)\n",
        "  fig.update_layout(title_text=name)\n",
        "\n",
        "  fig.show()\n",
        "\n",
        "\n",
        "# RSI\n",
        "def draw_rsi(stock_name, stock_data):\n",
        "  fig = plt.subplots(figsize=(10, 6), sharex=True)\n",
        "  gs = gridspec.GridSpec(nrows=2, ncols=1, height_ratios=[2, 1])\n",
        "\n",
        "  # 주가 나타내기\n",
        "  ax1 = plt.subplot(gs[0])\n",
        "  ax1 = stock_data['Close'].plot()\n",
        "  ax1.set_xlabel('')\n",
        "  ax1.axes.xaxis.set_ticks([])\n",
        "  plt.title(stock_name)\n",
        "\n",
        "  # RSI 나타내기\n",
        "  ax2 = plt.subplot(gs[1])\n",
        "  ax2 = stock_data['RSI_14'].plot(color='black', ylim=[0, 100])\n",
        "  ax2.axhline(y=70, color='r', linestyle='-')\n",
        "  ax2.axhline(y=30, color='r', linestyle='-')\n",
        "  ax2.set_xlabel\n",
        "  plt.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "  plt.show()\n",
        "  return stock_data\n",
        "\n",
        "def draw_bbbands(stock_name, stock_data):\n",
        "  band = ta.bbands(stock_data[\"Close\"], length=20, std=2)\n",
        "  bb = pd.concat([band[['BBL_20_2.0', 'BBM_20_2.0', 'BBU_20_2.0']], stock_data['Close']], axis = 1)\n",
        "  bb.columns = ['Lower Band', 'Mid Band', 'Upper Band', 'Close']\n",
        "  bb.plot(figsize=(10, 6),\n",
        "          color={\n",
        "              'Upper Band': 'red',\n",
        "              'Lower Band': 'blue',\n",
        "              'Mid Band': 'green',\n",
        "              'Close': 'black'\n",
        "          })\n",
        "  plt.title(stock_name)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bi_iJPP78zOH"
      },
      "source": [
        "모든 반도체 종목에 대해 캔들차트 그리기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49EMn2L1BZdK"
      },
      "outputs": [],
      "source": [
        "name = '자람테크놀로지'\n",
        "draw_sma_ema(name,get_stockdata(stock[name]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9zcxOP9Lgm3"
      },
      "outputs": [],
      "source": [
        "# for name, value in stock.items():\n",
        "#   draw_bbbands(name,draw_rsi(name,draw_ema(name,draw_sma(name,match_dfshape(get_stockdata(value),'2021-01-01','2024-03-13')))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Djxce3rPrb5r"
      },
      "outputs": [],
      "source": [
        "draw_sma_ema(name,get_stockdata('123010'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "X3fSLMGLoHIQ"
      },
      "outputs": [],
      "source": [
        "for name, value in stock.items():\n",
        "  print(name)\n",
        "  draw_sma_ema(name,get_stockdata(value))\n",
        "# print(get_stockdata('005930'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaNbSSLmM7Ik"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "stock_df[datetime.strptime('2023-03','%Y-%m')+relativedelta(months=1):]"
      ],
      "metadata": {
        "id": "CUHO2kEdF54p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.loc['2022/12'].loc['매출액']\n",
        "stock_df.loc[:idx_date,'매출액'] = df.loc['2022/12','매출액']"
      ],
      "metadata": {
        "id": "eFBR8xlRImSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcHCdMtyx-T0"
      },
      "source": [
        "# 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mR5_VBoVyAHa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68yywJ0GyD4c"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(128)\n",
        "MinMaxScaler = MinMaxScaler()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
        "    super(LSTM, self).__init__()\n",
        "    self.num_classes = num_classes #number of classes\n",
        "    self.num_layers = num_layers #number of layers\n",
        "    self.input_size = input_size #input size\n",
        "    self.hidden_size = hidden_size #hidden state\n",
        "    self.seq_length = seq_length #sequence length\n",
        "\n",
        "    self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
        "                      num_layers=num_layers, batch_first=True) #lstm\n",
        "    self.fc_1 =  nn.Linear(hidden_size, 128) #fully connected 1\n",
        "    self.fc = nn.Linear(128, num_classes) #fully connected last layer\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self,x):\n",
        "    h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) #hidden state\n",
        "    c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) #internal state\n",
        "    # Propagate input through LSTM\n",
        "\n",
        "    output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
        "\n",
        "    hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
        "    out = self.relu(hn)\n",
        "    out = self.fc_1(out) #first Dense\n",
        "    out = self.relu(out) #relu\n",
        "    out = self.fc(out) #Final Output\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "igVjG_in3zvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU(nn.Module) :\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length) :\n",
        "        super(GRU, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.num_layers = num_layers\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "        self.gru = nn.GRU(input_size=input_size,hidden_size=hidden_size,\n",
        "                         num_layers=num_layers,batch_first=True)\n",
        "        self.fc_1 = nn.Linear(hidden_size, 128)\n",
        "        self.fc = nn.Linear(128, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x) :\n",
        "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
        "        output, (hn) = self.gru(x, (h_0))\n",
        "        hn = hn.view(-1, self.hidden_size)\n",
        "        out = self.relu(hn)\n",
        "        out = self.fc_1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "vYW0t3975UlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30000 #1000 epochs\n",
        "learning_rate = 0.00001 #0.001 lr\n",
        "\n",
        "input_size = 5 #number of features\n",
        "hidden_size = 2 #number of features in hidden state\n",
        "num_layers = 1 #number of stacked lstm layers\n",
        "\n",
        "num_classes = 1 #number of output classes"
      ],
      "metadata": {
        "id": "bNSf861S4Dv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = LSTM(num_classes, input_size, hidden_size, num_layers, X_train_tensors_final.shape[1]).to(device)\n",
        "\n",
        "loss_function = torch.nn.MSELoss()    # mean-squared error for regression\n",
        "optimizer = torch.optim.Adam(lstm1.parameters(), lr=learning_rate)  # adam optimizer"
      ],
      "metadata": {
        "id": "lEwpfAUm4HUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  outputs = lstm.forward(X_train_tensors_final.to(device)) #forward pass\n",
        "  optimizer.zero_grad() #caluclate the gradient, manually setting to 0\n",
        "\n",
        "  # obtain the loss function\n",
        "  loss = loss_function(outputs, y_train_tensors.to(device))\n",
        "\n",
        "  loss.backward() #calculates the loss of the loss function\n",
        "\n",
        "  optimizer.step() #improve from loss, i.e backprop\n",
        "  if epoch % 100 == 0:\n",
        "    print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
      ],
      "metadata": {
        "id": "84D1hCfW4vuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_X_ss = ss.transform(df.drop(columns='Volume'))\n",
        "df_y_mm = mm.transform(df.iloc[:, 5:6])\n",
        "\n",
        "df_X_ss = Variable(torch.Tensor(df_X_ss)) #converting to Tensors\n",
        "df_y_mm = Variable(torch.Tensor(df_y_mm))\n",
        "#reshaping the dataset\n",
        "df_X_ss = torch.reshape(df_X_ss, (df_X_ss.shape[0], 1, df_X_ss.shape[1]))"
      ],
      "metadata": {
        "id": "eeDDivGX4yZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict = lstm(df_X_ss.to(device))#forward pass\n",
        "data_predict = train_predict.data.detach().cpu().numpy() #numpy conversion\n",
        "dataY_plot = df_y_mm.data.numpy()\n",
        "\n",
        "data_predict = mm.inverse_transform(data_predict) #reverse transformation\n",
        "dataY_plot = mm.inverse_transform(dataY_plot)\n",
        "plt.figure(figsize=(10,6)) #plotting\n",
        "plt.axvline(x=4500, c='r', linestyle='--') #size of the training set\n",
        "\n",
        "plt.plot(dataY_plot, label='Actuall Data') #actual plot\n",
        "plt.plot(data_predict, label='Predicted Data') #predicted plot\n",
        "plt.title('Time-Series Prediction')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8lpZ0lrX42J2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1s2rSxjRWnMMnHl76dcV5rYx-42ZkdnRl",
      "authorship_tag": "ABX9TyPdSm3Z+hbJbCHbqEUMacGs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}